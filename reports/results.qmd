---
title: "Results"
format:
  html: { toc: false }
  pdf: { toc: false, pdf-engine: tectonic }
  docx: default
  gfm: default
freeze: auto
execute:
  echo: false
---

```{r}
#| label: setup
library(yaml)
library(here)

fmt3 <- function(x) sprintf("%.3f", x)
fmt6 <- function(x) sprintf("%.6f", x)

cleaning <- yaml::read_yaml(here("outputs", "results", "cleaning.yml"))
base <- yaml::read_yaml(here("outputs", "results", "base_lm.yml"))
complexity <- yaml::read_yaml(here("outputs", "results", "visual_complexity_penalty.yml"))
```

## Cleaning

The pipeline kept `r cleaning$counts$kept_trials` of `r cleaning$counts$total_trials` trials (dropped `r cleaning$counts$dropped_trials`).
Settings: correct-only = `r cleaning$trimming$correct_only`, RT range = `r cleaning$trimming$rt_min_ms`–`r cleaning$trimming$rt_max_ms` ms.

```{r}
#| label: cleaning-table
data.frame(
  setting = c(
    "correct_only",
    "rt_min_ms",
    "rt_max_ms",
    "total_trials",
    "kept_trials",
    "dropped_trials"
  ),
  value = c(
    as.character(cleaning$trimming$correct_only),
    cleaning$trimming$rt_min_ms,
    cleaning$trimming$rt_max_ms,
    cleaning$counts$total_trials,
    cleaning$counts$kept_trials,
    cleaning$counts$dropped_trials
  )
)
```

```{r}
#| label: rt-hist
knitr::include_graphics(here("outputs", "figures", "rt_hist.png"))
```

## Baseline model: frequency and strokes

```{r}
#| label: base-table
data.frame(
  term = c("intercept", "log_freq", "strokes"),
  estimate = c(
    fmt6(as.numeric(base$coefficients$intercept)),
    fmt6(as.numeric(base$coefficients$log_freq)),
    fmt6(as.numeric(base$coefficients$strokes))
  )
)
```

R² `r fmt3(as.numeric(base$r2))`; adjusted R² `r fmt3(as.numeric(base$adj_r2))`; residual sigma `r fmt3(as.numeric(base$sigma))`.
AIC `r fmt3(as.numeric(base$aic))`, BIC `r fmt3(as.numeric(base$bic))`.

## Visual complexity penalty

The partial effect of strokes remains reliable after holding frequency at its median (`r complexity$reference_log_freq`). The smooth term uses `r fmt3(as.numeric(complexity$edf_strokes))` effective degrees of freedom (F = `r fmt3(as.numeric(complexity$f_strokes))`, p = `r fmt6(as.numeric(complexity$p_strokes))`). The predicted range from the least to most complex characters implies a `r fmt3(as.numeric(complexity$penalty$log_rt))` increase in log RT (about `r fmt3(as.numeric(complexity$penalty$rt_ms))` ms). The strongest penalty lies between `r complexity$penalty$range_strokes$min` and `r complexity$penalty$range_strokes$max` strokes (top `r complexity$penalty$percentile * 100`% of the effect curve).

```{r}
#| label: complexity-table
data.frame(
  metric = c("edf (strokes)", "F statistic", "p-value", "log RT span", "RT span (ms)", "penalty strokes min", "penalty strokes max"),
  value = c(
    fmt3(as.numeric(complexity$edf_strokes)),
    fmt3(as.numeric(complexity$f_strokes)),
    fmt6(as.numeric(complexity$p_strokes)),
    fmt6(as.numeric(complexity$penalty$log_rt)),
    fmt3(as.numeric(complexity$penalty$rt_ms)),
    complexity$penalty$range_strokes$min,
    complexity$penalty$range_strokes$max
  )
)
```

```{r}
#| label: complexity-partial
knitr::include_graphics(here("outputs", "figures", "visual_complexity_penalty.png"))
```

<!--
To add another analysis:
1) create scripts/NN_slug.R that writes outputs/results/slug.yml
2) add a Makefile rule and add it to ANALYSES
3) copy this section, rename, and read slug.yml
Keep computation out of the QMD.
-->
